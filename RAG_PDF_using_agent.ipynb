{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Install necessary libraries"
      ],
      "metadata": {
        "id": "7fHl_Wk7OMVx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MOlxttXFOJp9",
        "outputId": "84357f82-6b80-4a76-f1e7-62ae2f68bb69"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m815.9/815.9 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m226.7/226.7 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m23.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m284.0/284.0 kB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.6/17.6 MB\u001b[0m \u001b[31m48.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m66.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m241.2/241.2 kB\u001b[0m \u001b[31m26.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.4/56.4 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.9/75.9 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.0/77.0 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.4/55.4 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mCollecting langchain-openai\n",
            "  Downloading langchain_openai-0.0.6-py3-none-any.whl (29 kB)\n",
            "Requirement already satisfied: langchain-core<0.2,>=0.1.16 in /usr/local/lib/python3.10/dist-packages (from langchain-openai) (0.1.23)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain-openai) (1.25.2)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from langchain-openai) (1.12.0)\n",
            "Requirement already satisfied: tiktoken<1,>=0.5.2 in /usr/local/lib/python3.10/dist-packages (from langchain-openai) (0.6.0)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1.16->langchain-openai) (6.0.1)\n",
            "Requirement already satisfied: anyio<5,>=3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1.16->langchain-openai) (3.7.1)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1.16->langchain-openai) (1.33)\n",
            "Requirement already satisfied: langsmith<0.0.88,>=0.0.87 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1.16->langchain-openai) (0.0.87)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1.16->langchain-openai) (23.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1.16->langchain-openai) (2.6.1)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1.16->langchain-openai) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1.16->langchain-openai) (8.2.3)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai<2.0.0,>=1.10.0->langchain-openai) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.10.0->langchain-openai) (0.26.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.10.0->langchain-openai) (1.3.0)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.10.0->langchain-openai) (4.66.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.10.0->langchain-openai) (4.9.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken<1,>=0.5.2->langchain-openai) (2023.12.25)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1.16->langchain-openai) (3.6)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1.16->langchain-openai) (1.2.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.10.0->langchain-openai) (2024.2.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.10.0->langchain-openai) (1.0.3)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.10.0->langchain-openai) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.2,>=0.1.16->langchain-openai) (2.4)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core<0.2,>=0.1.16->langchain-openai) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core<0.2,>=0.1.16->langchain-openai) (2.16.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-core<0.2,>=0.1.16->langchain-openai) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-core<0.2,>=0.1.16->langchain-openai) (2.0.7)\n",
            "Installing collected packages: langchain-openai\n",
            "Successfully installed langchain-openai-0.0.6\n"
          ]
        }
      ],
      "source": [
        "!pip -q install langchain openai tiktoken pypdf faiss-cpu langchainhub\n",
        "!pip install -U langchain-openai"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Declare OPENAI API KEY"
      ],
      "metadata": {
        "id": "oFzNP6H7O5Bw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"\""
      ],
      "metadata": {
        "id": "c6IjHy_OOgZ9"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain_openai import ChatOpenAI,OpenAIEmbeddings\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain import hub\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "from langchain_core.runnables import RunnableParallel\n",
        "from langchain_core.runnables import RunnableLambda\n",
        "from langchain_core.chat_history import BaseChatMessageHistory\n",
        "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
        "\n",
        "from langchain.schema import format_document\n",
        "from langchain_core.messages import AIMessage, HumanMessage, get_buffer_string\n",
        "from langchain_core.runnables import RunnableParallel, RunnablePassthrough\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from operator import itemgetter\n",
        "from langchain.memory import ConversationBufferMemory"
      ],
      "metadata": {
        "id": "psjBPM0KO3N2"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "PATH = \"/content/1.pdf\" #your PDF path\n",
        "\n",
        "loader = PyPDFLoader(PATH)\n",
        "pages = loader.load_and_split()\n",
        "\n",
        "#pages will contain metadata like page and source pdf as well"
      ],
      "metadata": {
        "id": "gsjVIfZwRj5Y"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now split the full text into chunks"
      ],
      "metadata": {
        "id": "npUzwWRGULd5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Splitting up the text into smaller chunks for indexing\n",
        "text_splitter = CharacterTextSplitter(\n",
        "    separator = \"\\n\",\n",
        "    chunk_size = 1000,\n",
        "    chunk_overlap  = 200, #striding over the text\n",
        "    length_function = len,\n",
        ")\n"
      ],
      "metadata": {
        "id": "kJt1qCEApk4i"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs_new = text_splitter.split_documents(pages)\n"
      ],
      "metadata": {
        "id": "fORTC1But9gi"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(docs_new)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4V0LPTpbL3NL",
        "outputId": "6e191603-9005-472f-8b02-a2050567c733"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "49"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "docs_new[17].page_content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 103
        },
        "id": "k3J6MXGs3erS",
        "outputId": "6425b3b2-c100-4e6a-bf66-8c055d9ac325"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'ChengduEbyteElectronicTechnologyCo,;Ltd E32-433T30Dusermanual\\nCopyright©2012–2019，ChengduEbyteElectronicTechnologyCo.,Ltd. 8\\n5Functiondescription\\n5.1Fixedtransmission\\n5.2Broadcastingtransmission\\n5.3Broadcastingaddress\\n\\uf06cForexample:SettheaddressofmoduleAas0xFFFF,andthechannelas0x04;\\n\\uf06cWhenmoduleisthetransmitter(transparenttransmission),allmodulesunderchannel0x04willreceivethedata,the'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "docs_new[17].metadata"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xhV9JZH4uMWn",
        "outputId": "8115bf16-3479-4383-e1cf-15e28d3c720c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'source': '/content/1.pdf', 'page': 8}"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now Embeddings of the data"
      ],
      "metadata": {
        "id": "LIuH9IpP5VPh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings = OpenAIEmbeddings()"
      ],
      "metadata": {
        "id": "1DnejlSM4Lyl"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "db = FAISS.from_documents(docs_new, embeddings)"
      ],
      "metadata": {
        "id": "i32IkH2v5iY7"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Retriever"
      ],
      "metadata": {
        "id": "xunOSMcNXA9d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "retriever = db.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 6})"
      ],
      "metadata": {
        "id": "Hd7u7xaY4xmN"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "retriever"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4lUvHEfvRnEJ",
        "outputId": "8fdfe06d-b08b-4e61-a8bf-c0fa452fc906"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VectorStoreRetriever(tags=['FAISS', 'OpenAIEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x7da214bc7040>, search_kwargs={'k': 6})"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "RAG using agent"
      ],
      "metadata": {
        "id": "ju0hH8kMb1eU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from langchain.tools.retriever import create_retriever_tool\n",
        "\n",
        "tool = create_retriever_tool(\n",
        "    retriever,\n",
        "    \"search_about_E32_from_available_document\",\n",
        "    \"Searches and returns excerpts about E32 mentioned in the document given.\"\n",
        ")\n",
        "\n",
        "tools = [tool]"
      ],
      "metadata": {
        "id": "IL3IJZtJb3vI"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tools"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HO9f4gJPHC0p",
        "outputId": "5bddfcd3-4072-40f4-d011-75220c264283"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Tool(name='search_about_E32_from_available_document', description='Searches and returns excerpts about E32 mentioned in the document given.', args_schema=<class 'langchain.tools.retriever.RetrieverInput'>, func=functools.partial(<function _get_relevant_documents at 0x7d2e5c06d240>, retriever=VectorStoreRetriever(tags=['FAISS', 'OpenAIEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x7d2e5c478ac0>, search_kwargs={'k': 6}), document_prompt=PromptTemplate(input_variables=['page_content'], template='{page_content}'), document_separator='\\n\\n'), coroutine=functools.partial(<function _aget_relevant_documents at 0x7d2e5c06d360>, retriever=VectorStoreRetriever(tags=['FAISS', 'OpenAIEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x7d2e5c478ac0>, search_kwargs={'k': 6}), document_prompt=PromptTemplate(input_variables=['page_content'], template='{page_content}'), document_separator='\\n\\n'))]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "from langchain import hub\n",
        "\n",
        "prompt = hub.pull(\"hwchase17/openai-tools-agent\")\n",
        "prompt.messages"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TEBIO-WuckOr",
        "outputId": "e7a90816-2bac-481b-eb65-94ab41cd8839"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='You are a helpful assistant')),\n",
              " MessagesPlaceholder(variable_name='chat_history', optional=True),\n",
              " HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='{input}')),\n",
              " MessagesPlaceholder(variable_name='agent_scratchpad')]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "llm = ChatOpenAI(temperature=0)"
      ],
      "metadata": {
        "id": "uMcfn5J9dIlL"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "from langchain.agents import AgentExecutor, create_openai_tools_agent\n",
        "\n",
        "agent = create_openai_tools_agent(llm, tools, prompt)\n",
        "agent_executor = AgentExecutor(agent=agent, tools =  tools)\n",
        "\n"
      ],
      "metadata": {
        "id": "xelwZ5TCeFby"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = agent_executor.invoke({\"input\": \"what is E32 in mentioned document?\"})"
      ],
      "metadata": {
        "id": "WYq9esORgWg5"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result[\"output\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 103
        },
        "id": "XgnsSc35ga1Q",
        "outputId": "708b3f39-ae81-4458-90dc-a765a183a3d5"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'E32 is mentioned in the document \"E32-433T30D User Manual\" from Chengdu Ebyte Electronic Technology Co., Ltd. It appears to be a wireless module with different variations such as E32-915T30DSX1276915M, E32-170T30DSX1278170M, E32-868T20DSX1276868M, E32-915T20DSX1276915M, E32-433T20DCSX1278433M, and E32-433T30DSX1278433M. The document provides information about the specifications, features, and limitations of these modules.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result = agent_executor.invoke({\"input\": \"who manufacture E32 and what are some specifications of it?\"})"
      ],
      "metadata": {
        "id": "_EhGoQ3tF1MZ"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result[\"output\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "GJyUfmckH2lB",
        "outputId": "042a9f62-25ae-428b-d509-628acf9769fa"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"The E32 is manufactured by Chengdu Ebyte Electronic Technology Co., Ltd. Unfortunately, I couldn't find detailed specifications for the E32 module in the available documents.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.chat_message_histories import ChatMessageHistory\n",
        "from langchain_core.runnables.history import RunnableWithMessageHistory"
      ],
      "metadata": {
        "id": "AP8heVxNH4kT"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "message_history = ChatMessageHistory()"
      ],
      "metadata": {
        "id": "xvTJHY3KS5i9"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent_with_chat_history = RunnableWithMessageHistory(\n",
        "    agent_executor,\n",
        "    # This is needed because in most real world scenarios, a session id is needed\n",
        "    # It isn't really used here because we are using a simple in memory ChatMessageHistory\n",
        "    lambda session_id: message_history,\n",
        "    input_messages_key=\"input\",\n",
        "    history_messages_key=\"chat_history\",\n",
        ")"
      ],
      "metadata": {
        "id": "9dC13n-_Wpxk"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent_with_chat_history.invoke(\n",
        "    {\"input\": \"what is E32 in mentioned document?\"},\n",
        "    # This is needed because in most real world scenarios, a session id is needed\n",
        "    # It isn't really used here because we are using a simple in memory ChatMessageHistory\n",
        "    config={\"configurable\": {\"session_id\": \"<foo>\"}},\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KB_F4ygdTC6B",
        "outputId": "25e59843-6743-4be4-d35d-2a8b855e18bc"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input': 'what is E32 in mentioned document?',\n",
              " 'chat_history': [HumanMessage(content=\"hi! I'm bob\"),\n",
              "  AIMessage(content='Hello Bob! How can I assist you today?'),\n",
              "  HumanMessage(content=\"what's my name?\"),\n",
              "  AIMessage(content='Your name is Bob.')],\n",
              " 'output': 'In the mentioned document, there are references to E32-915T30DSX1276915M, E32-170T30DSX1278170M, E32-868T20DSX1276868M, E32-915T20DSX1276915M, E32-433T20DCSX1278433M, and E32-433T30DSX1278433M. These are different models or versions of E32 wireless modules. The document also includes a user manual for the E32-433T30D module, which provides information about its specifications, features, and usage instructions.'}"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "agent_with_chat_history.invoke(\n",
        "    {\"input\": \"who manufacture it?\"},\n",
        "    # This is needed because in most real world scenarios, a session id is needed\n",
        "    # It isn't really used here because we are using a simple in memory ChatMessageHistory\n",
        "    config={\"configurable\": {\"session_id\": \"<foo>\"}},\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MVprI7BQTHM8",
        "outputId": "8773ab0e-793f-427f-89e8-993b907e7cd3"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input': 'who manufacture it?',\n",
              " 'chat_history': [HumanMessage(content=\"hi! I'm bob\"),\n",
              "  AIMessage(content='Hello Bob! How can I assist you today?'),\n",
              "  HumanMessage(content=\"what's my name?\"),\n",
              "  AIMessage(content='Your name is Bob.'),\n",
              "  HumanMessage(content='what is E32 in mentioned document?'),\n",
              "  AIMessage(content='In the mentioned document, there are references to E32-915T30DSX1276915M, E32-170T30DSX1278170M, E32-868T20DSX1276868M, E32-915T20DSX1276915M, E32-433T20DCSX1278433M, and E32-433T30DSX1278433M. These are different models or versions of E32 wireless modules. The document also includes a user manual for the E32-433T30D module, which provides information about its specifications, features, and usage instructions.'),\n",
              "  HumanMessage(content='who manufacture it?'),\n",
              "  AIMessage(content='The manufacturer of the E32 wireless modules is Ebyte.')],\n",
              " 'output': 'The manufacturer of the E32 wireless modules is Chengdu Ebyte Electronic Technology Co., Ltd.'}"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Kbe5AtgKTLO2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}