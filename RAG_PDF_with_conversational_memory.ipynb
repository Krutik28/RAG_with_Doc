{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Install necessary libraries"
      ],
      "metadata": {
        "id": "7fHl_Wk7OMVx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MOlxttXFOJp9",
        "outputId": "497e9747-3529-478b-ff67-18bbdf985c6a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m806.7/806.7 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m226.1/226.1 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m284.0/284.0 kB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.6/17.6 MB\u001b[0m \u001b[31m36.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m50.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m238.5/238.5 kB\u001b[0m \u001b[31m24.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.4/55.4 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mCollecting langchain-openai\n",
            "  Downloading langchain_openai-0.0.5-py3-none-any.whl (29 kB)\n",
            "Requirement already satisfied: langchain-core<0.2,>=0.1.16 in /usr/local/lib/python3.10/dist-packages (from langchain-openai) (0.1.21)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain-openai) (1.23.5)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from langchain-openai) (1.11.1)\n",
            "Requirement already satisfied: tiktoken<0.6.0,>=0.5.2 in /usr/local/lib/python3.10/dist-packages (from langchain-openai) (0.5.2)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1.16->langchain-openai) (6.0.1)\n",
            "Requirement already satisfied: anyio<5,>=3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1.16->langchain-openai) (3.7.1)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1.16->langchain-openai) (1.33)\n",
            "Requirement already satisfied: langsmith<0.0.88,>=0.0.87 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1.16->langchain-openai) (0.0.87)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1.16->langchain-openai) (23.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1.16->langchain-openai) (2.6.0)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1.16->langchain-openai) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1.16->langchain-openai) (8.2.3)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai<2.0.0,>=1.10.0->langchain-openai) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.10.0->langchain-openai) (0.25.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.10.0->langchain-openai) (1.3.0)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.10.0->langchain-openai) (4.66.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.10.0->langchain-openai) (4.9.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken<0.6.0,>=0.5.2->langchain-openai) (2023.12.25)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1.16->langchain-openai) (3.6)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1.16->langchain-openai) (1.2.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.10.0->langchain-openai) (2024.2.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.10.0->langchain-openai) (1.0.2)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.10.0->langchain-openai) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.2,>=0.1.16->langchain-openai) (2.4)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core<0.2,>=0.1.16->langchain-openai) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core<0.2,>=0.1.16->langchain-openai) (2.16.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-core<0.2,>=0.1.16->langchain-openai) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-core<0.2,>=0.1.16->langchain-openai) (2.0.7)\n",
            "Installing collected packages: langchain-openai\n",
            "Successfully installed langchain-openai-0.0.5\n"
          ]
        }
      ],
      "source": [
        "!pip -q install langchain openai tiktoken pypdf faiss-cpu langchainhub\n",
        "!pip install -U langchain-openai"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Chain with chat history\n",
        "\n",
        "ASTRA DB as database\n",
        "One can choose any based on the requirement\n",
        "\n",
        "Available options:\n",
        "\"AstraDBChatMessageHistory\",\n",
        "    \"ChatMessageHistory\",\n",
        "    \"CassandraChatMessageHistory\",\n",
        "    \"CosmosDBChatMessageHistory\",\n",
        "    \"DynamoDBChatMessageHistory\",\n",
        "    \"ElasticsearchChatMessageHistory\",\n",
        "    \"FileChatMessageHistory\",\n",
        "    \"FirestoreChatMessageHistory\",\n",
        "    \"MomentoChatMessageHistory\",\n",
        "    \"MongoDBChatMessageHistory\",\n",
        "    \"PostgresChatMessageHistory\",\n",
        "    \"RedisChatMessageHistory\",\n",
        "    \"RocksetChatMessageHistory\",\n",
        "    \"SQLChatMessageHistory\",\n",
        "    \"StreamlitChatMessageHistory\",\n",
        "    \"SingleStoreDBChatMessageHistory\",\n",
        "    \"XataChatMessageHistory\",\n",
        "    \"ZepChatMessageHistory\",\n",
        "    \"UpstashRedisChatMessageHistory\",\n",
        "    \"Neo4jChatMessageHistory\",\n",
        "    \"TiDBChatMessageHistory\","
      ],
      "metadata": {
        "id": "VVxNqepTRuWK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install --upgrade --quiet  \"astrapy>=0.6.2\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m1o6_gvOZs4L",
        "outputId": "fd094fb6-0f45-4dab-b7d0-17cad3c9d339"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/40.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.3/40.3 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.0/75.0 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.8/18.8 MB\u001b[0m \u001b[31m42.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import getpass\n",
        "\n",
        "ASTRA_DB_API_ENDPOINT = input(\"ASTRA_DB_API_ENDPOINT = \")\n",
        "ASTRA_DB_APPLICATION_TOKEN = getpass.getpass(\"ASTRA_DB_APPLICATION_TOKEN = \")"
      ],
      "metadata": {
        "id": "sLpjeLA0aFCh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Declare OPENAI API KEY"
      ],
      "metadata": {
        "id": "oFzNP6H7O5Bw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"\""
      ],
      "metadata": {
        "id": "c6IjHy_OOgZ9"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain_openai import ChatOpenAI,OpenAIEmbeddings\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain import hub\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "from langchain_core.runnables import RunnableParallel\n",
        "from langchain_core.runnables import RunnableLambda\n",
        "from langchain_core.chat_history import BaseChatMessageHistory\n",
        "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
        "\n",
        "from langchain.schema import format_document\n",
        "from langchain_core.messages import AIMessage, HumanMessage, get_buffer_string\n",
        "from langchain_core.runnables import RunnableParallel, RunnablePassthrough\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from operator import itemgetter\n",
        "from langchain.memory import ConversationBufferMemory"
      ],
      "metadata": {
        "id": "psjBPM0KO3N2"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "PATH = \"/content/1.pdf\" #your PDF path\n",
        "\n",
        "loader = PyPDFLoader(PATH)\n",
        "pages = loader.load_and_split()\n",
        "\n",
        "#pages will contain metadata like page and source pdf as well"
      ],
      "metadata": {
        "id": "gsjVIfZwRj5Y"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now split the full text into chunks"
      ],
      "metadata": {
        "id": "npUzwWRGULd5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Splitting up the text into smaller chunks for indexing\n",
        "text_splitter = CharacterTextSplitter(\n",
        "    separator = \"\\n\",\n",
        "    chunk_size = 1000,\n",
        "    chunk_overlap  = 200, #striding over the text\n",
        "    length_function = len,\n",
        ")\n"
      ],
      "metadata": {
        "id": "kJt1qCEApk4i"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs_new = text_splitter.split_documents(pages)\n"
      ],
      "metadata": {
        "id": "fORTC1But9gi"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(docs_new)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4V0LPTpbL3NL",
        "outputId": "0f4c2237-41a6-43cb-acbb-502b178d11f0"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "49"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "docs_new[17].page_content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 103
        },
        "id": "k3J6MXGs3erS",
        "outputId": "645ad5de-3fde-4558-ff9a-7bdf2e91691c"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'ChengduEbyteElectronicTechnologyCo,;Ltd E32-433T30Dusermanual\\nCopyright©2012–2019，ChengduEbyteElectronicTechnologyCo.,Ltd. 8\\n5Functiondescription\\n5.1Fixedtransmission\\n5.2Broadcastingtransmission\\n5.3Broadcastingaddress\\n\\uf06cForexample:SettheaddressofmoduleAas0xFFFF,andthechannelas0x04;\\n\\uf06cWhenmoduleisthetransmitter(transparenttransmission),allmodulesunderchannel0x04willreceivethedata,the'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "docs_new[17].metadata"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xhV9JZH4uMWn",
        "outputId": "466a3c5b-5568-4a04-97fe-297ebba4f1b4"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'source': '/content/1.pdf', 'page': 8}"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now Embeddings of the data"
      ],
      "metadata": {
        "id": "LIuH9IpP5VPh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings = OpenAIEmbeddings()"
      ],
      "metadata": {
        "id": "1DnejlSM4Lyl"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "db = FAISS.from_documents(docs_new, embeddings)"
      ],
      "metadata": {
        "id": "i32IkH2v5iY7"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Retriever"
      ],
      "metadata": {
        "id": "xunOSMcNXA9d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "retriever = db.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 6})"
      ],
      "metadata": {
        "id": "Hd7u7xaY4xmN"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "retriever"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4lUvHEfvRnEJ",
        "outputId": "7414dddd-a196-40ed-ef6e-0c8c3ed1f3d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VectorStoreRetriever(tags=['FAISS', 'OpenAIEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x7bdb35607e20>, search_kwargs={'k': 6})"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts.prompt import PromptTemplate\n",
        "\n",
        "_template = \"\"\"Given the following conversation and a follow up question, rephrase the follow up question to be a standalone question, in its original language.\n",
        "If chat history is empty please don't change the question\n",
        "\n",
        "Chat History:\n",
        "{chat_history}\n",
        "Follow Up Input: {question}\n",
        "Standalone question:\"\"\"\n",
        "\n",
        "condense_question_prompt = PromptTemplate.from_template(_template)"
      ],
      "metadata": {
        "id": "KN1AmTuwDFSE"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "template =  \"\"\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise. context:\n",
        "{context}\n",
        "\n",
        "Question: {question}\n",
        "\"\"\"\n",
        "\n",
        "answer_prompt = ChatPromptTemplate.from_template(template)\n",
        "\n",
        "default_doc_template =PromptTemplate.from_template(template = '{page_content}')"
      ],
      "metadata": {
        "id": "06WQmsDqDkLu"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def _combine_documents(\n",
        "    docs, document_prompt=default_doc_template, document_separator=\"\\n\\n\"\n",
        "):\n",
        "    doc_strings = [format_document(doc, document_prompt) for doc in docs]\n",
        "    return document_separator.join(doc_strings)"
      ],
      "metadata": {
        "id": "vZ4fRfL2QJG_"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#if want to use local ConversationBufferMemory buffer:\n",
        "memory = ConversationBufferMemory(\n",
        "    return_messages = True, output_key = \"answer\", input_key = \"question\",\n",
        ")"
      ],
      "metadata": {
        "id": "tAQfYafcWVD4"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#or if you want to save it on cloud :\n",
        "from langchain.memory import AstraDBChatMessageHistory\n",
        "\n",
        "message_history = AstraDBChatMessageHistory(\n",
        "    session_id=\"test-session\",\n",
        "    api_endpoint=ASTRA_DB_API_ENDPOINT,\n",
        "    token=ASTRA_DB_APPLICATION_TOKEN,\n",
        ")\n",
        "\n",
        "memory = ConversationBufferMemory(\n",
        "        memory_key=\"history\",\n",
        "        chat_memory=message_history,\n",
        "        return_messages=True,\n",
        "        output_key=\"answer\",\n",
        "        input_key=\"question\"\n",
        "    )\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "I-pyrJWQZ8Sf"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "memory.load_memory_variables({})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zvbYHpjvkHNY",
        "outputId": "62244d94-ae6f-456e-8195-7795d2437053"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'history': [HumanMessage(content='hi!'), AIMessage(content='whats up?')]}"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "loaded_memory = RunnablePassthrough.assign(\n",
        "    chat_history = RunnableLambda(memory.load_memory_variables) | itemgetter(\"history\"),\n",
        ")"
      ],
      "metadata": {
        "id": "rAMJ9X2NZ9R7"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "standalone_question = {\n",
        "    \"standalone_question\": {\n",
        "        \"question\": lambda x: x[\"question\"],\n",
        "        \"chat_history\": lambda x: get_buffer_string(x[\"chat_history\"]),\n",
        "    }\n",
        "    | condense_question_prompt\n",
        "    | ChatOpenAI(temperature=0)\n",
        "    | StrOutputParser(),\n",
        "\n",
        "}\n",
        "\n",
        "retrieved_docs = {\n",
        "    \"docs\": itemgetter(\"standalone_question\") | retriever,\n",
        "    \"question\": lambda x: x[\"standalone_question\"],\n",
        "}\n",
        "\n",
        "final_inputs = {\n",
        "    \"context\":lambda x: _combine_documents(x[\"docs\"]),\n",
        "    \"question\": itemgetter(\"question\"),\n",
        "}\n",
        "# And finally, we do the part that returns the answers\n",
        "answer = {\n",
        "    \"answer\": final_inputs | answer_prompt | ChatOpenAI(temperature=0),\n",
        "    \"docs\": itemgetter(\"docs\"),\n",
        "}\n",
        "\n",
        "\n",
        "final_chain = loaded_memory | standalone_question | retrieved_docs | answer"
      ],
      "metadata": {
        "id": "QkLdGFORabVD"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Invoke chain"
      ],
      "metadata": {
        "id": "7yC5wMfDmEZ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = {\"question\": \"Who manufature E32?\"}\n",
        "result = final_chain.invoke(inputs)\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XDGMh56hdGFK",
        "outputId": "393fe6bb-bb06-448c-e103-302373c6109a"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'answer': AIMessage(content='Chengdu Ebyte Electronic Technology Co., Ltd manufactures E32.'), 'docs': [Document(page_content='E32-915T30DSX1276915M 30 80.3~19.2kDIP24*43SMA-K\\nE32-170T30DSX1278170M 30 80.3k~9.6kDIP24*43SMA-K\\nE32-868T20DSX1276868M 20 30.3~19.2kDIP21*36SMA-K\\nE32-915T20DSX1276915M 20 30.3~19.2kDIP21*36SMA-K\\nE32-433T20DCSX1278433M 20 30.3k~19.2kDIP21*36SMA-K\\nE32-433T30DSX1278433M 30 80.3k~19.2kDIP24*43SMA-K', metadata={'source': '/content/1.pdf', 'page': 18}), Document(page_content='ChengduEbyteElectronicTechnologyCo,;Ltd E32-433T30Dusermanual\\nCopyright©2012–2019，ChengduEbyteElectronicTechnologyCo.,Ltd. 3\\nDisclaimer\\nEBYTEreservesallrightstothisdocumentandtheinformationcontainedherein.\\nProducts,names,logosanddesignsdescribedhereinmayinwholeorinpartbe\\nsubjecttointellectualpropertyrights.Reproduction,use,modificationordisclosureto\\nthirdpartiesofthisdocumentoranypartthereofwithouttheexpresspermissionof\\nEBYTEisstrictlyprohibited.\\nTheinformationcontainedhereinisprovided“asis”andEBYTEassumesno\\nliabilityfortheuseoftheinformation.Nowarranty,eitherexpressorimplied,isgiven,\\nincludingbutnotlimited,withrespecttotheaccuracy,correctness,reliabilityand\\nfitnessforaparticularpurposeoftheinformation.Thisdocumentmayberevisedby\\nEBYTEatanytime.Formostrecentdocuments,visitwww.ebyte.com.', metadata={'source': '/content/1.pdf', 'page': 3}), Document(page_content='ChengduEbyteElectronicTechnologyCo,;Ltd E32-433T30Dusermanual\\nCopyright©2012–2019，ChengduEbyteElectronicTechnologyCo.,Ltd. 2\\nREVISIONHISTORY.......................................................................................................................21\\nABOUTUS..........................................................................................................................................21', metadata={'source': '/content/1.pdf', 'page': 2}), Document(page_content='E32-433T30DUserManual\\nSX1278433MHz1WDIPWirelessModule', metadata={'source': '/content/1.pdf', 'page': 0}), Document(page_content='ChengduEbyteElectronicTechnologyCo,;Ltd E32-433T30Dusermanual\\nCopyright©2012–2019，ChengduEbyteElectronicTechnologyCo.,Ltd. 21\\nRevisionhistory\\nVersion Date Description Issuedby\\n1.00 2017-11-10 Initialversion huaa\\n1.10 2018-01-11 UpdatingE32(868T30S)/E32(915T30S) huaa\\n1.20 2018-01-15 UpdatingE32(868T20S)/E32(915T20S)/E32(400T20S) huaa\\n1.30 2018-01-22UpdatingE32(868T20D)/E32(868T30D)\\nE32(915T20D)/E32(915T30D)/E32(170T30D)huaa\\n1.40 2018-05-24 Updatingantennaoption huaa\\n1.50 2018-10-11 Manualdividing huaa\\n1.60 2020-04-13 Ren\\n1.8 2020-10-23 Parametercorrection Linson\\nAboutus\\nTechnicalsupport:support@cdebyte.com\\nDocumentsandRFSettingdownloadlink:www.ebyte.com\\nThankyouforusingEbyteproducts!Pleasecontactuswithanyquestionsorsuggestions:info@cdebyte.com\\n------------------------------------------------------------------------------------------------------------\\nFax:028-64146160ext.821\\nWeb:www.ebyte.com\\nAddress:BuildingB5,MouldIndustrialPark,199#XiquAvenue,Chengdu,Sichuan', metadata={'source': '/content/1.pdf', 'page': 21}), Document(page_content='ChengduEbyteElectronicTechnologyCo,;Ltd E32-433T30Dusermanual\\nCopyright©2012–2019，ChengduEbyteElectronicTechnologyCo.,Ltd. 20\\n13Packageforbatchorder', metadata={'source': '/content/1.pdf', 'page': 20})]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "memory.save_context(inputs, {\"answer\": result[\"answer\"].content})"
      ],
      "metadata": {
        "id": "ywBwZRucZhbp"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "memory.load_memory_variables({})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dQVL1Fztmkf7",
        "outputId": "1e8b258a-c233-469d-9d28-2b7359354564"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'history': [HumanMessage(content='hi!'),\n",
              "  AIMessage(content='whats up?'),\n",
              "  HumanMessage(content='What is E32 ?'),\n",
              "  AIMessage(content='The given context does not provide information about what \"E32\" means.'),\n",
              "  HumanMessage(content='Who manufature E32?'),\n",
              "  AIMessage(content='Chengdu Ebyte Electronic Technology Co., Ltd manufactures E32.')]}"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "G5JVCE4DmtfL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}